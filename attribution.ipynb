{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1947f0ae-041b-46a2-a629-9f5f40f6d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "returns = pd.read_csv('data/returns.csv')\n",
    "tickers = list(returns.columns)[1:]  \n",
    "\n",
    "data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        row = {\n",
    "            'Ticker': ticker,\n",
    "            'MarketCap': info.get('marketCap', 0),\n",
    "            'Sector': info.get('sector', 'Unknown'),\n",
    "            'Country': info.get('country', 'Unknown')\n",
    "        }\n",
    "        data.append(row)\n",
    "        time.sleep(1.5)  \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving {ticker}: {e}\")\n",
    "        data.append({'Ticker': ticker, 'MarketCap': 0, 'Sector': 'Unknown', 'Country': 'Unknown'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cd67ac2-29d2-421e-a516-4591d24d9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Size classification\n",
    "df['SmallCap'] = (df['MarketCap'] < 2e15).astype(int)\n",
    "df['MidCap'] = ((df['MarketCap'] >= 2e15) & (df['MarketCap'] < 1e20)).astype(int)\n",
    "df['LargeCap'] = (df['MarketCap'] >= 1e20).astype(int)\n",
    "\n",
    "\n",
    "# Sector classification\n",
    "df['Tech'] = df['Sector'].str.contains('Technology', case=False, na=False).astype(int)\n",
    "df['Finance'] = df['Sector'].str.contains('Financial|Bank', case=False, na=False).astype(int)\n",
    "df['Healthcare'] = df['Sector'].str.contains('Health', case=False, na=False).astype(int)\n",
    "df['Consumer'] = df['Sector'].str.contains('Consumer', case=False, na=False).astype(int)\n",
    "df['Energy'] = df['Sector'].str.contains('Energy|Oil|Gas', case=False, na=False).astype(int)\n",
    "df['Industrial'] = df['Sector'].str.contains('Industrials', case=False, na=False).astype(int)\n",
    "df['Utilities'] = df['Sector'].str.contains('Utilities', case=False, na=False).astype(int)\n",
    "\n",
    "# Country classification\n",
    "df['International'] = (df['Country'] != 'United States').astype(int)\n",
    "df['Domestic'] = (df['Country'] == 'United States').astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24449a32-a699-45ff-9651-acd7e472e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = df[['Ticker', 'SmallCap', 'MidCap', 'LargeCap',\n",
    "                'Tech', 'Finance', 'Healthcare', 'Consumer',\n",
    "                'Energy', 'Industrial', 'Utilities',\n",
    "                'International', 'Domestic']]\n",
    "\n",
    "binary_df.to_csv(\"data/ticker_attributes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e02ceaf-3f49-4a7b-b29d-48357d78e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#generate data file\n",
    "\n",
    "binary_df = pd.read_csv('data/ticker_attributes.csv')\n",
    "\n",
    "binary_df = binary_df.set_index(\"Ticker\")\n",
    "tickers = binary_df.index.tolist()\n",
    "features = binary_df.columns.tolist()\n",
    "\n",
    "# Example target vector \n",
    "targets = {\n",
    "    \"Tech\": 0.3,\n",
    "    \"Finance\": 0.2,\n",
    "    \"Healthcare\": .05,\n",
    "    \"Consumer\": .05,\n",
    "    \"Utilities\": .1,\n",
    "    \"Energy\": .1,\n",
    "    \"Industrial\": .1,\n",
    "    \"SmallCap\": 0.25,\n",
    "    \"MidCap\": 0.25,\n",
    "    \"LargeCap\": 0.5,\n",
    "    \"Domestic\": 0.7,\n",
    "    \"International\": 0.3\n",
    "}\n",
    "\n",
    "\n",
    "#example weights (replace with max_corr weights)\n",
    "x_orig = {ticker: 1 / len(tickers) for ticker in tickers}\n",
    "\n",
    "# Write AMPL-compatible .dat file\n",
    "with open(\"attributes.dat\", \"w\") as f_out:\n",
    "    # STOCKS\n",
    "    f_out.write(\"set STOCKS := \" + \" \".join(tickers) + \" ;\\n\\n\")\n",
    "\n",
    "    # FEATURES\n",
    "    f_out.write(\"set FEATURES := \" + \" \".join(features) + \" ;\\n\\n\")\n",
    "\n",
    "    # x_orig\n",
    "    f_out.write(\"param x_orig :=\\n\")\n",
    "    for t in tickers:\n",
    "        f_out.write(f\"  {t} {x_orig[t]:.6f}\\n\")\n",
    "    f_out.write(\";\\n\\n\")\n",
    "\n",
    "    # Feature matrix: param a\n",
    "    f_out.write(\"param a : \" + \" \".join(features) + \" :=\\n\")\n",
    "    for t in tickers:\n",
    "        row = \" \".join(str(int(binary_df.loc[t, feat])) for feat in features)\n",
    "        f_out.write(f\"{t} {row}\\n\")\n",
    "    f_out.write(\";\\n\\n\")\n",
    "\n",
    "    # Feature targets: param f\n",
    "    f_out.write(\"param f :=\\n\")\n",
    "    for feat in features:\n",
    "        f_out.write(f\"  {feat} {targets[feat]:.6f}\\n\")\n",
    "    f_out.write(\";\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0741bd65-b07a-41b9-b844-6d20289d6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from amplpy import AMPL\n",
    "\n",
    "def run_attribute_rebalanced_index(ms):\n",
    "    # Load data\n",
    "    returns = pd.read_csv(\"data/returns.csv\", index_col=0)\n",
    "    sp100_returns = pd.read_csv(\"data/sp100returns.csv\")\n",
    "    combined = sp100_returns[['Portfolio_Return']].rename(columns={'Portfolio_Return': 'SP100'})\n",
    "    \n",
    "    # Load feature matrix\n",
    "    binary_df = pd.read_csv(\"data/ticker_attributes.csv\").set_index(\"Ticker\")\n",
    "    all_features = binary_df.columns.tolist()\n",
    "\n",
    "    # Load custom weights from file\n",
    "    weights_df = pd.read_csv(\"data/sp100weights.csv\").set_index(\"Ticker\")\n",
    "\n",
    "    for m in ms:\n",
    "        # Split into IS and OOS\n",
    "        split_point = int(0.7 * len(returns))\n",
    "        out_sample = returns.iloc[split_point:].copy()\n",
    "        n_rows = len(out_sample)\n",
    "        period_length = n_rows // m\n",
    "        periods = np.repeat(np.arange(1, m + 1), period_length)\n",
    "        if n_rows % m != 0:\n",
    "            periods = np.append(periods, [m] * (n_rows - len(periods)))\n",
    "        out_sample['period'] = periods\n",
    "\n",
    "        # Convert OOS to long format\n",
    "        out_sample_tall = out_sample.reset_index().melt(\n",
    "            id_vars=[\"Date\", \"period\"],\n",
    "            var_name=\"Ticker\",\n",
    "            value_name=\"Return\"\n",
    "        )\n",
    "\n",
    "        # Create IS windows\n",
    "        is_windows = []\n",
    "        for i in range(1, m + 1):\n",
    "            start_date = out_sample[out_sample['period'] == i].index[0]\n",
    "            is_window = returns.loc[:start_date].iloc[-split_point:]\n",
    "            is_windows.append(is_window)\n",
    "\n",
    "        # Run AMPL model for each rebalancing period\n",
    "        for i in range(m):\n",
    "            window_returns = is_windows[i]\n",
    "            tickers = list(window_returns.columns)\n",
    "\n",
    "            # Use only relevant features\n",
    "            available = [feat for feat in all_features if binary_df.loc[tickers, feat].sum() > 0]\n",
    "            if not available:\n",
    "                print(f\"(m={m}) period {i+1}: ❌ No usable features found — skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Get weights for current tickers from file\n",
    "            valid_weights = weights_df.loc[tickers]['Weight']\n",
    "            valid_weights = valid_weights / valid_weights.sum()  # Normalize\n",
    "\n",
    "            # Compute weighted attribute targets\n",
    "            sub_df = binary_df.loc[tickers, available]\n",
    "            target_dict = (sub_df.T @ valid_weights).round(6).to_dict()\n",
    "\n",
    "            # Write AMPL data file\n",
    "            with open(\"attributes.dat\", \"w\") as f:\n",
    "                f.write(\"set STOCKS := \" + \" \".join(tickers) + \" ;\\n\\n\")\n",
    "                f.write(\"set FEATURES := \" + \" \".join(available) + \" ;\\n\\n\")\n",
    "\n",
    "                f.write(\"param x_orig :=\\n\")\n",
    "                for t in tickers:\n",
    "                    f.write(f\"  {t} {valid_weights[t]:.6f}\\n\")\n",
    "                f.write(\";\\n\\n\")\n",
    "\n",
    "                f.write(\"param a : \" + \" \".join(available) + \" :=\\n\")\n",
    "                for t in tickers:\n",
    "                    row = \" \".join(str(int(binary_df.loc[t, feat])) for feat in available)\n",
    "                    f.write(f\"{t} {row}\\n\")\n",
    "                f.write(\";\\n\\n\")\n",
    "\n",
    "                f.write(\"param f :=\\n\")\n",
    "                for feat in available:\n",
    "                    f.write(f\"  {feat} {target_dict[feat]:.6f}\\n\")\n",
    "                f.write(\";\\n\")\n",
    "\n",
    "            # Solve optimization\n",
    "            ampl = AMPL()\n",
    "            ampl.setOption(\"solver\", \"gurobi\")\n",
    "            ampl.read(\"attributes.mod.txt\")\n",
    "            ampl.readData(\"attributes.dat\")\n",
    "            ampl.solve()\n",
    "\n",
    "            x = ampl.getVariable(\"x\").getValues().to_pandas()\n",
    "            nonzero = x[x[\"x.val\"] > 0]\n",
    "            print(f\"(m={m}) period {i+1}: ✅ solution found with {len(nonzero)} non-zero weights\")\n",
    "\n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c6f65c2-0e77-4593-9d93-ff43672ee9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=2) period 1: ✅ solution found with 100 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=2) period 2: ✅ solution found with 100 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=4) period 1: ✅ solution found with 100 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=4) period 2: ✅ solution found with 100 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=4) period 3: ✅ solution found with 100 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "103 simplex iterations\n",
      "(m=4) period 4: ✅ solution found with 100 non-zero weights\n"
     ]
    }
   ],
   "source": [
    "combined_returns = run_attribute_rebalanced_index(ms=[2, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3126b6da-3ca1-4084-8822-64d72ef85676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from amplpy import AMPL\n",
    "\n",
    "def run_attribute_rebalanced_index(q, ms):\n",
    "    # Load data\n",
    "    returns = pd.read_csv(\"data/returns.csv\", index_col=0)\n",
    "    sp100_returns = pd.read_csv(\"data/sp100returns.csv\")\n",
    "    combined = sp100_returns[['Portfolio_Return']].rename(columns={'Portfolio_Return': 'SP100'})\n",
    "\n",
    "    binary_df = pd.read_csv(\"data/ticker_attributes.csv\").set_index(\"Ticker\")\n",
    "    all_features = binary_df.columns.tolist()\n",
    "\n",
    "    for m in ms:\n",
    "        # Split into IS and OOS\n",
    "        split_point = int(0.7 * len(returns))\n",
    "        out_sample = returns.iloc[split_point:].copy()\n",
    "        n_rows = len(out_sample)\n",
    "        period_length = n_rows // m\n",
    "        periods = np.repeat(np.arange(1, m + 1), period_length)\n",
    "        if n_rows % m != 0:\n",
    "            periods = np.append(periods, [m] * (n_rows - len(periods)))\n",
    "        out_sample['period'] = periods\n",
    "        out_sample_tall = out_sample.reset_index().melt(\n",
    "            id_vars=[\"Date\", \"period\"],\n",
    "            var_name=\"Ticker\",\n",
    "            value_name=\"Return\"\n",
    "        )\n",
    "\n",
    "        # Create IS windows\n",
    "        is_windows = []\n",
    "        for i in range(1, m + 1):\n",
    "            start_date = out_sample[out_sample['period'] == i].index[0]\n",
    "            is_window = returns.loc[:start_date].iloc[-split_point:]\n",
    "            is_windows.append(is_window)\n",
    "\n",
    "        # Run selection + attribute optimization per period\n",
    "        for i in range(m):\n",
    "            window_returns = is_windows[i]\n",
    "            correlations = window_returns.corr()\n",
    "            tickers = list(correlations.columns)\n",
    "\n",
    "            # Step 1: run max_corr model to select top q tickers\n",
    "            with open(\"data.txt\", \"w\") as f:\n",
    "                f.write(\"set STOCKS := \" + \" \".join(tickers) + \" ;\\n\\n\")\n",
    "                f.write(\"param q := \" + str(q) + \" ;\\n\\n\")\n",
    "                f.write(\"param r:\\n    \" + \" \".join(tickers) + \" :=\\n\")\n",
    "                for t1 in tickers:\n",
    "                    row = \" \".join(f\"{correlations.loc[t1, t2]:.4f}\" for t2 in tickers)\n",
    "                    f.write(f\"{t1} {row}\\n\")\n",
    "                f.write(\";\\n\")\n",
    "\n",
    "            ampl = AMPL()\n",
    "            ampl.setOption(\"solver\", \"gurobi\")\n",
    "            ampl.read(\"max_corr.txt\")  # Your max_corr.mod file\n",
    "            ampl.readData(\"data.txt\")\n",
    "            ampl.solve()\n",
    "            y = ampl.getVariable(\"y\").getValues().to_pandas()\n",
    "            selected = y[y[\"y.val\"] == 1].index.tolist()\n",
    "\n",
    "            if not selected:\n",
    "                print(f\"(q={q}, m={m}) period {i+1}: ❌ No tickers selected — skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Step 2: calculate market cap weights\n",
    "            market_caps = {}\n",
    "            for ticker in selected:\n",
    "                try:\n",
    "                    info = yf.Ticker(ticker).info\n",
    "                    market_caps[ticker] = info.get('marketCap', 0)\n",
    "                except:\n",
    "                    market_caps[ticker] = 0\n",
    "            total_cap = sum(market_caps.values())\n",
    "            weights = {t: market_caps[t] / total_cap if total_cap > 0 else 0 for t in selected}\n",
    "\n",
    "            # Step 3: derive attribute targets\n",
    "            available = [feat for feat in all_features if binary_df.loc[selected, feat].sum() > 0]\n",
    "            if not available:\n",
    "                print(f\"(q={q}, m={m}) period {i+1}: ❌ No usable features found — skipping.\")\n",
    "                continue\n",
    "\n",
    "            sub_df = binary_df.loc[selected, available]\n",
    "            weight_vec = pd.Series(weights).reindex(sub_df.index)\n",
    "            target_dict = (sub_df.T @ weight_vec).round(6).to_dict()\n",
    "\n",
    "            # Step 4: write .dat file\n",
    "            with open(\"attributes.dat\", \"w\") as f:\n",
    "                f.write(\"set STOCKS := \" + \" \".join(selected) + \" ;\\n\\n\")\n",
    "                f.write(\"set FEATURES := \" + \" \".join(available) + \" ;\\n\\n\")\n",
    "\n",
    "                f.write(\"param x_orig :=\\n\")\n",
    "                for t in selected:\n",
    "                    f.write(f\"  {t} {weights[t]:.6f}\\n\")\n",
    "                f.write(\";\\n\\n\")\n",
    "\n",
    "                f.write(\"param a : \" + \" \".join(available) + \" :=\\n\")\n",
    "                for t in selected:\n",
    "                    row = \" \".join(str(int(binary_df.loc[t, feat])) for feat in available)\n",
    "                    f.write(f\"{t} {row}\\n\")\n",
    "                f.write(\";\\n\\n\")\n",
    "\n",
    "                f.write(\"param f :=\\n\")\n",
    "                for feat in available:\n",
    "                    f.write(f\"  {feat} {target_dict[feat]:.6f}\\n\")\n",
    "                f.write(\";\\n\")\n",
    "\n",
    "            # Step 5: solve attribute model\n",
    "            ampl = AMPL()\n",
    "            ampl.setOption(\"solver\", \"gurobi\")\n",
    "            ampl.read(\"attributes.mod.txt\")\n",
    "            ampl.readData(\"attributes.dat\")\n",
    "            ampl.solve()\n",
    "\n",
    "            x = ampl.getVariable(\"x\").getValues().to_pandas()\n",
    "            nonzero = x[x[\"x.val\"] > 0]\n",
    "            print(f\"(q={q}, m={m}) period {i+1}: ✅ solution found with {len(nonzero)} non-zero weights\")\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f172658-f6b9-49bf-9af5-1010f110341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi 12.0.1: optimal solution; objective 77.2324\n",
      "581 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "18 simplex iterations\n",
      "(q=15, m=2) period 1: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 70.7877\n",
      "601 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 1e-06\n",
      "23 simplex iterations\n",
      "(q=15, m=2) period 2: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 77.2324\n",
      "581 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "18 simplex iterations\n",
      "(q=15, m=4) period 1: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 71.7706\n",
      "612 simplex iterations\n",
      "1 branching node\n",
      "absmipgap=0.00715, relmipgap=9.9623e-05\n",
      "Gurobi 12.0.1: optimal solution; objective 9.999999999e-07\n",
      "19 simplex iterations\n",
      "(q=15, m=4) period 2: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 70.6739\n",
      "599 simplex iterations\n",
      "1 branching node\n",
      "absmipgap=0.0052, relmipgap=7.35774e-05\n",
      "Gurobi 12.0.1: optimal solution; objective 2e-06\n",
      "21 simplex iterations\n",
      " \n",
      "------------ WARNINGS ------------\n",
      "WARNING:  \"Tolerance violations\"\n",
      "  Type                         MaxAbs [Name]   MaxRel [Name]\n",
      "* algebraic con(s)             1E-06           4E-05         \n",
      "*: Using the solver's aux variable values.\n",
      "Documentation: mp.ampl.com/modeling-tools.html#automatic-solution-check.\n",
      "(q=15, m=4) period 3: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 69.7719\n",
      "585 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "15 simplex iterations\n",
      "(q=15, m=4) period 4: ✅ solution found with 15 non-zero weights\n"
     ]
    }
   ],
   "source": [
    "combined_returns = run_attribute_rebalanced_index(q=15, ms=[2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd0a1d90-f523-4266-b3d6-b2e2138b5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from amplpy import AMPL\n",
    "\n",
    "def run_attribute_rebalanced_index(qs, ms):\n",
    "    returns = pd.read_csv(\"data/returns.csv\", index_col=0)\n",
    "    sp100_returns = pd.read_csv(\"data/sp100returns.csv\")\n",
    "    combined = sp100_returns[['Portfolio_Return']].rename(columns={'Portfolio_Return': 'SP100'})\n",
    "\n",
    "    binary_df = pd.read_csv(\"data/ticker_attributes.csv\").set_index(\"Ticker\")\n",
    "    all_features = binary_df.columns.tolist()\n",
    "\n",
    "    for q in qs:\n",
    "        for m in ms:\n",
    "            print(f\"\\n>>> Processing q={q}, m={m}\")\n",
    "            split_point = int(0.7 * len(returns))\n",
    "            out_sample = returns.iloc[split_point:].copy()\n",
    "            n_rows = len(out_sample)\n",
    "            period_length = n_rows // m\n",
    "            periods = np.repeat(np.arange(1, m + 1), period_length)\n",
    "            if n_rows % m != 0:\n",
    "                periods = np.append(periods, [m] * (n_rows - len(periods)))\n",
    "            out_sample['period'] = periods\n",
    "            out_sample_tall = out_sample.reset_index().melt(\n",
    "                id_vars=[\"Date\", \"period\"], var_name=\"Ticker\", value_name=\"Return\"\n",
    "            )\n",
    "\n",
    "            is_windows = []\n",
    "            for i in range(1, m + 1):\n",
    "                start_date = out_sample[out_sample['period'] == i].index[0]\n",
    "                is_window = returns.loc[:start_date].iloc[-split_point:]\n",
    "                is_windows.append(is_window)\n",
    "\n",
    "            all_portfolio_returns = []\n",
    "\n",
    "            for i in range(m):\n",
    "                window_returns = is_windows[i]\n",
    "                correlations = window_returns.corr()\n",
    "                tickers = list(correlations.columns)\n",
    "\n",
    "                # Step 1: run max_corr to select q tickers\n",
    "                with open(\"data.txt\", \"w\") as f:\n",
    "                    f.write(\"set STOCKS := \" + \" \".join(tickers) + \" ;\\n\\n\")\n",
    "                    f.write(\"param q := \" + str(q) + \" ;\\n\\n\")\n",
    "                    f.write(\"param r:\\n    \" + \" \".join(tickers) + \" :=\\n\")\n",
    "                    for t1 in tickers:\n",
    "                        row = \" \".join(f\"{correlations.loc[t1, t2]:.4f}\" for t2 in tickers)\n",
    "                        f.write(f\"{t1} {row}\\n\")\n",
    "                    f.write(\";\\n\")\n",
    "\n",
    "                ampl = AMPL()\n",
    "                ampl.setOption(\"solver\", \"gurobi\")\n",
    "                ampl.read(\"max_corr.txt\")  # Your max_corr.mod file\n",
    "                ampl.readData(\"data.txt\")\n",
    "                ampl.solve()\n",
    "\n",
    "                y = ampl.getVariable(\"y\").getValues().to_pandas()\n",
    "                selected = y[y[\"y.val\"] == 1].index.tolist()\n",
    "\n",
    "                if not selected:\n",
    "                    print(f\"(q={q}, m={m}) period {i+1}: No tickers selected — skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Step 2: calculate market cap weights\n",
    "                market_caps = {}\n",
    "                for ticker in selected:\n",
    "                    try:\n",
    "                        info = yf.Ticker(ticker).info\n",
    "                        market_caps[ticker] = info.get('marketCap', 0)\n",
    "                    except:\n",
    "                        market_caps[ticker] = 0\n",
    "                total_cap = sum(market_caps.values())\n",
    "                weights = {t: market_caps[t] / total_cap if total_cap > 0 else 0 for t in selected}\n",
    "\n",
    "                # Step 3: build attribute targets\n",
    "                available = [feat for feat in all_features if binary_df.loc[selected, feat].sum() > 0]\n",
    "                if not available:\n",
    "                    print(f\"(q={q}, m={m}) period {i+1}: No usable features — skipping.\")\n",
    "                    continue\n",
    "\n",
    "                sub_df = binary_df.loc[selected, available]\n",
    "                weight_vec = pd.Series(weights).reindex(sub_df.index)\n",
    "                target_dict = (sub_df.T @ weight_vec).round(6).to_dict()\n",
    "\n",
    "                # Step 4: write attributes.dat for AMPL\n",
    "                with open(\"attributes.dat\", \"w\") as f:\n",
    "                    f.write(\"set STOCKS := \" + \" \".join(selected) + \" ;\\n\\n\")\n",
    "                    f.write(\"set FEATURES := \" + \" \".join(available) + \" ;\\n\\n\")\n",
    "\n",
    "                    f.write(\"param x_orig :=\\n\")\n",
    "                    for t in selected:\n",
    "                        f.write(f\"  {t} {weights[t]:.6f}\\n\")\n",
    "                    f.write(\";\\n\\n\")\n",
    "\n",
    "                    f.write(\"param a : \" + \" \".join(available) + \" :=\\n\")\n",
    "                    for t in selected:\n",
    "                        row = \" \".join(str(int(binary_df.loc[t, feat])) for feat in available)\n",
    "                        f.write(f\"{t} {row}\\n\")\n",
    "                    f.write(\";\\n\\n\")\n",
    "\n",
    "                    f.write(\"param f :=\\n\")\n",
    "                    for feat in available:\n",
    "                        f.write(f\"  {feat} {target_dict[feat]:.6f}\\n\")\n",
    "                    f.write(\";\\n\")\n",
    "\n",
    "                # Step 5: solve attribute optimization\n",
    "                ampl = AMPL()\n",
    "                ampl.setOption(\"solver\", \"gurobi\")\n",
    "                ampl.read(\"attributes.mod.txt\")\n",
    "                ampl.readData(\"attributes.dat\")\n",
    "                ampl.solve()\n",
    "\n",
    "                x = ampl.getVariable(\"x\").getValues().to_pandas()\n",
    "                nonzero = x[x[\"x.val\"] > 0].reset_index()\n",
    "                nonzero = nonzero.rename(columns={nonzero.columns[0]: \"Ticker\", nonzero.columns[1]: \"x.val\"})\n",
    "\n",
    "                nonzero[\"Weight\"] = nonzero[\"x.val\"]\n",
    "                nonzero[\"period\"] = i + 1\n",
    "                all_portfolio_returns.append(nonzero)\n",
    "\n",
    "                print(f\"(q={q}, m={m}) period {i+1}: solution found with {len(nonzero)} non-zero weights\")\n",
    "\n",
    "            # Step 6: combine results and calculate return\n",
    "            if all_portfolio_returns:\n",
    "                weights_df = pd.concat(all_portfolio_returns)\n",
    "                portfolio = pd.merge(out_sample_tall, weights_df, on=['period', 'Ticker'], how='inner')\n",
    "                portfolio['Weighted_Return'] = portfolio['Return'] * portfolio['Weight']\n",
    "                portfolio_return = portfolio.groupby('Date')['Weighted_Return'].sum().reset_index()\n",
    "                portfolio_return = portfolio_return.rename(columns={'Weighted_Return': 'Portfolio_Return'})\n",
    "                label = f\"(q={q}, m={m})\"\n",
    "                combined[label] = portfolio_return['Portfolio_Return']\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77956f24-ca28-4f41-af70-80b1ffeb40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing q=5, m=2\n",
      "Gurobi 12.0.1: optimal solution; objective 70.6261\n",
      "894 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "2 simplex iterations\n",
      "(q=5, m=2) period 1: ✅ solution found with 5 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 61.6403\n",
      "1203 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "2 simplex iterations\n",
      "(q=5, m=2) period 2: ✅ solution found with 5 non-zero weights\n",
      "\n",
      ">>> Processing q=5, m=4\n",
      "Gurobi 12.0.1: optimal solution; objective 70.6261\n",
      "894 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "2 simplex iterations\n",
      "(q=5, m=4) period 1: ✅ solution found with 5 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 63.3561\n",
      "1110 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "6 simplex iterations\n",
      "(q=5, m=4) period 2: ✅ solution found with 5 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 61.5819\n",
      "1281 simplex iterations\n",
      "1 branching node\n",
      "absmipgap=0.00555, relmipgap=9.01239e-05\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "2 simplex iterations\n",
      "(q=5, m=4) period 3: ✅ solution found with 5 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 60.1916\n",
      "1164 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: infeasible problem\n",
      "8 simplex iterations\n",
      "\n",
      "suffix dunbdd OUT;\n",
      "(q=5, m=4) period 4: ✅ solution found with 5 non-zero weights\n",
      "\n",
      ">>> Processing q=15, m=2\n",
      "Gurobi 12.0.1: optimal solution; objective 77.2324\n",
      "581 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "18 simplex iterations\n",
      "(q=15, m=2) period 1: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 70.7877\n",
      "601 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 1e-06\n",
      "23 simplex iterations\n",
      "(q=15, m=2) period 2: ✅ solution found with 15 non-zero weights\n",
      "\n",
      ">>> Processing q=15, m=4\n",
      "Gurobi 12.0.1: optimal solution; objective 77.2324\n",
      "581 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "18 simplex iterations\n",
      "(q=15, m=4) period 1: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 71.7706\n",
      "612 simplex iterations\n",
      "1 branching node\n",
      "absmipgap=0.00715, relmipgap=9.9623e-05\n",
      "Gurobi 12.0.1: optimal solution; objective 9.999999999e-07\n",
      "19 simplex iterations\n",
      "(q=15, m=4) period 2: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 70.6739\n",
      "599 simplex iterations\n",
      "1 branching node\n",
      "absmipgap=0.0052, relmipgap=7.35774e-05\n",
      "Gurobi 12.0.1: optimal solution; objective 2e-06\n",
      "21 simplex iterations\n",
      " \n",
      "------------ WARNINGS ------------\n",
      "WARNING:  \"Tolerance violations\"\n",
      "  Type                         MaxAbs [Name]   MaxRel [Name]\n",
      "* algebraic con(s)             1E-06           4E-05         \n",
      "*: Using the solver's aux variable values.\n",
      "Documentation: mp.ampl.com/modeling-tools.html#automatic-solution-check.\n",
      "(q=15, m=4) period 3: ✅ solution found with 15 non-zero weights\n",
      "Gurobi 12.0.1: optimal solution; objective 69.7719\n",
      "585 simplex iterations\n",
      "1 branching node\n",
      "Gurobi 12.0.1: optimal solution; objective 0\n",
      "15 simplex iterations\n",
      "(q=15, m=4) period 4: ✅ solution found with 15 non-zero weights\n"
     ]
    }
   ],
   "source": [
    "combined_returns = run_attribute_rebalanced_index(qs=[5,15], ms=[2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80798a-a9ec-457b-a943-2f1171b2c4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
