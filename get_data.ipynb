{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticker returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the tickers for SP-100\n",
    "url = \"https://en.wikipedia.org/wiki/S%26P_100\"\n",
    "\n",
    "# Read the tables on the page\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "tickers = tables[2]['Symbol'].tolist()\n",
    "tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "\n",
    "\n",
    "# Download weekly adjusted close prices\n",
    "stock_prices         = yf.download(tickers, start=\"2020-01-01\", end=\"2023-12-31\", auto_adjust = False)\n",
    "stock_prices = stock_prices.resample('W').last()\n",
    "stock_prices.index   = stock_prices.index.tz_localize(None)      # change yf date format to match pdr\n",
    "stock_prices         = stock_prices.filter(like='Adj Close')\n",
    "\n",
    "# Drop columns with too many missing values (e.g. due to IPOs)\n",
    "stock_prices = stock_prices.dropna(axis=1, thresh=int(0.9 * len(stock_prices)))\n",
    "\n",
    "returns = stock_prices.pct_change().dropna().rename(columns={\"Adj Close\": \"Return\"})\n",
    "returns = returns.xs('Return', axis=1, level=0)\n",
    "returns.columns.name = None\n",
    "\n",
    "\n",
    "returns.to_csv(\"data/returns.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SP100 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(0.7 * len(returns))\n",
    "out_sample =returns.iloc[split_point:].copy()\n",
    "out_sample_tall = out_sample.reset_index().melt(id_vars=[\"Date\"], var_name=\"Ticker\", value_name=\"Return\")\n",
    "market_caps = {}\n",
    "selected_tickers = returns.columns\n",
    "for ticker in selected_tickers:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        market_caps[ticker] = info.get('marketCap', 0)\n",
    "    except Exception as e:\n",
    "        market_caps[ticker] = 0\n",
    "total_market_value = sum(market_caps.values())\n",
    "\n",
    "tickers = []\n",
    "weights_list = []\n",
    "for ticker in selected_tickers:\n",
    "    cap = market_caps[ticker]\n",
    "    weight = cap / total_market_value\n",
    "    tickers.append(ticker)\n",
    "    weights_list.append(weight)\n",
    "\n",
    "sp_weights = pd.DataFrame({'Ticker': tickers, 'Weight': weights_list})\n",
    "sp_weights.to_csv(\"sp100weights.csv\")\n",
    "sp100 = pd.merge(out_sample_tall, sp_weights, on=['Ticker'], how='inner')\n",
    "sp100['Weighted_Return'] = sp100['Return'] * sp100['Weight']\n",
    "sp100_returns = sp100.groupby('Date')['Weighted_Return'].sum().reset_index()\n",
    "sp100_returns = sp100_returns.rename(columns={'Weighted_Return': 'Portfolio_Return'})\n",
    "\n",
    "sp100_returns.to_csv('data/sp100returns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list(returns.columns)[1:]  \n",
    "\n",
    "data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        row = {\n",
    "            'Ticker': ticker,\n",
    "            'MarketCap': info.get('marketCap', 0),\n",
    "            'Sector': info.get('sector', 'Unknown'),\n",
    "            'Country': info.get('country', 'Unknown')\n",
    "        }\n",
    "        data.append(row)\n",
    "        time.sleep(1)  \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving {ticker}: {e}\")\n",
    "        data.append({'Ticker': ticker, 'MarketCap': 0, 'Sector': 'Unknown', 'Country': 'Unknown'})\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Size classification\n",
    "df['SmallCap'] = (df['MarketCap'] < 2e9).astype(int)\n",
    "df['MidCap'] = ((df['MarketCap'] >= 2e9) & (df['MarketCap'] < 1e10)).astype(int)\n",
    "df['LargeCap'] = (df['MarketCap'] >= 1e10).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Sector classification\n",
    "df['Tech'] = df['Sector'].str.contains('Technology', case=False, na=False).astype(int)\n",
    "df['Finance'] = df['Sector'].str.contains('Financial|Bank', case=False, na=False).astype(int)\n",
    "df['Healthcare'] = df['Sector'].str.contains('Health', case=False, na=False).astype(int)\n",
    "df['Consumer'] = df['Sector'].str.contains('Consumer', case=False, na=False).astype(int)\n",
    "df['Energy'] = df['Sector'].str.contains('Energy|Oil|Gas', case=False, na=False).astype(int)\n",
    "df['Industrial'] = df['Sector'].str.contains('Industrials', case=False, na=False).astype(int)\n",
    "df['Utilities'] = df['Sector'].str.contains('Utilities', case=False, na=False).astype(int)\n",
    "\n",
    "# Country classification\n",
    "df['International'] = (df['Country'] != 'United States').astype(int)\n",
    "df['Domestic'] = (df['Country'] == 'United States').astype(int)\n",
    "\n",
    "binary_df = df[['Ticker', 'SmallCap', 'MidCap', 'LargeCap',\n",
    "                'Tech', 'Finance', 'Healthcare', 'Consumer',\n",
    "                'Energy', 'Industrial', 'Utilities',\n",
    "                'International', 'Domestic']]\n",
    "\n",
    "binary_df.to_csv(\"data/ticker_attributes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Index Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:Gurobi 12.0.1:"
     ]
    }
   ],
   "source": [
    "from attribution import attribute_index\n",
    "from max_corr import max_corr_index\n",
    "\n",
    "qs=[2, 3, 5, 7, 10, 15, 20, 25, 50]\n",
    "ms=[2]\n",
    "\n",
    "mc_corr, mc_returns = max_corr_index(qs, ms)\n",
    "\n",
    "corrs_df = pd.DataFrame(\n",
    "    [(q, m, corr) for (q, m), corr in mc_corr.items()],\n",
    "    columns=['q', 'm', 'Correlation']\n",
    ")\n",
    "\n",
    "corrs_df.to_csv('data/mc_corr.csv')\n",
    "mc_returns.to_csv('data/mc_ret.csv')\n",
    "\n",
    "# attributes\n",
    "\n",
    "att_corrs, combined_returns = attribute_index(qs, ms)\n",
    "\n",
    "corrs_df = pd.DataFrame(\n",
    "    [(q, m, corr) for (q, m), corr in att_corrs.items()],\n",
    "    columns=['q', 'm', 'Correlation']\n",
    ")\n",
    "\n",
    "corrs_df.to_csv('data/att_corr.csv')\n",
    "combined_returns.to_csv('data/att_ret.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
